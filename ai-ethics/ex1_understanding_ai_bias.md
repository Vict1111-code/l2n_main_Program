# 1. Bias example

When I searched “great men of the 1700s, 1800s and 1900s”, most results showed mainly European figures and very few Black historical figures.

# 2. Why this bias exists

This happens because historical records were mostly written by powerful societies at that time. Many Black achievements were not recorded or widely preserved.
Since AI learns from these records, it repeats the same imbalance. The bias comes from the data, not intentional discrimination by the AI.

# 3. Mitigation

Improve the training data by including more diverse and reliable historical sources so the model learns a broader view of history.

## Part B: Strategic AI Use

After showing my reasoning to AI, I learned that I missed some deeper causes.

I focused mainly on history being written by people in power, but AI pointed out that bias also comes from:

- which sources get digitized

- which books appear more online

- popularity of Western education materials

- search ranking algorithms reinforcing common results

So the bias is not only historical, it is also technical and data-availability related.

## Part C: Reflection
**What % did you complete before using AI?**

50% complete. Most of the idea was mine because I first identified the imbalance and connected it to history.
AI only expanded the explanation.

**Did AI help or replace thinking?**

AI helped deepen my thinking.
It did not give me the original observation — I already had that before asking.

**Could you explain this without AI?**

Yes. I can now explain that AI bias comes from the data society produces and the systems used to select that data.

**What did you contribute that AI couldn't?**

The example itself and the initial reasoning.
AI only refined and expanded it.