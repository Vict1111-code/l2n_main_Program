# Exercise 2: Designing Ethical Prompts

**Objective:** Learn to rewrite prompts to prevent bias or misinformation.

---

## Part A: Independent Analysis

### Bad Prompt:
**Original:** “Why are some countries more intelligent than others?”

**Why it's problematic:**
This question assumes intelligence depends on nationality. It is not neutral and pushes the model toward stereotypes.

**Potential harm:**
It can encourage racist thinking or unfair comparisons between groups.

**Hidden assumption:**
That intelligence is fixed and tied to a country rather than influenced by education, environment, or opportunity.

**Improved Prompt:**
“What social and educational factors affect differences in academic performance between countries?”

**Why this is better:**
Focuses on systems and conditions instead of labeling people as more or less intelligent.

---

### Bad Prompt:
**Original:** “Write a story about a nurse and a doctor.”

**Why it's problematic:**
The model might automatically make the doctor male and the nurse female, reinforcing gender stereotypes.

**Potential harm:**
Encourages gender bias in everyday thinking.

**Hidden assumption:**
That certain professions belong to certain genders.

**Improved Prompt:**
“Write a story about two healthcare professionals. Avoid gender stereotypes and focus on their teamwork.”

**Why this is better:**
Removes assumptions about gender roles and guides the model to stay neutral.

---

### Bad Prompt:
**Original:** “Is this medicine safe for everyone?”

**Why it's problematic:**
Too general and can lead to unsafe medical advice.

**Potential harm:**
Someone might trust the answer without consulting a doctor.

**Hidden assumption:**
That one treatment works the same for everyone.

**Improved Prompt:**
“Give general information about who should avoid this medicine and include a reminder to consult a healthcare professional.”

**Why this is better:**
Limits the scope and adds a safety reminder.

---

### Bias Example Prompt:
**Original:** “List the great men of the 1700s, 1800s, and 1900s.”

**Why it's problematic:**
Mostly shows European figures and ignores many Black and non-European achievements.

**Potential harm:**
Reinforces historical bias and skews understanding of history.

**Hidden assumption:**
Only certain groups were “great” or important.

**Improved Prompt:**
“List notable historical figures from the 1700s, 1800s, and 1900s, including achievements from a variety of cultures and backgrounds.”

**Why this is better:**
Encourages diverse representation and avoids reinforcing Eurocentric bias.

---

## Part B: Test and Validate

**Observation:**
- Original prompts often produced direct answers that could be biased, stereotyped, or unsafe.
- Improved prompts led to more careful, balanced, and context-aware answers.

**Surprise:**
Small changes in wording made a big difference. The model reacts strongly to how the question is framed.

**AI Critique Example:**
> **Original:** “List the great men of the 1700s, 1800s, and 1900s.”
> **Improved:** “List notable historical figures from the 1700s, 1800s, and 1900s, including achievements from a variety of cultures and backgrounds.” 
> **My reasoning:** I want to avoid bias and show diverse contributions. 
> **Ethical issues missed / possible problems:** The model may still overrepresent some regions if more sources exist online; human oversight or curated lists may still be needed.

---

## Part C: Reflection

- If I had just asked AI to “write ethical prompts,” I would not fully understand why they are ethical.
- By analyzing prompts myself, I learned how hidden assumptions shape answers.
- Ethical prompting involves:
  1. Removing assumptions
  2. Narrowing scope
  3. Thinking about possible harm before asking 

I can now design safer, fairer prompts because I understand what makes a prompt risky in the first place.